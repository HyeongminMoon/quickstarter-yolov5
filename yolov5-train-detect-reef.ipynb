{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 10344, done.\u001b[K\n",
      "remote: Total 10344 (delta 0), reused 0 (delta 0), pack-reused 10344\u001b[K\n",
      "Receiving objects: 100% (10344/10344), 10.58 MiB | 14.66 MiB/s, done.\n",
      "Resolving deltas: 100% (7141/7141), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv yolov5/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0-3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>2</td>\n",
       "      <td>29859</td>\n",
       "      <td>10755</td>\n",
       "      <td>2983</td>\n",
       "      <td>2-10755</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23497</th>\n",
       "      <td>2</td>\n",
       "      <td>29859</td>\n",
       "      <td>10756</td>\n",
       "      <td>2984</td>\n",
       "      <td>2-10756</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23498</th>\n",
       "      <td>2</td>\n",
       "      <td>29859</td>\n",
       "      <td>10757</td>\n",
       "      <td>2985</td>\n",
       "      <td>2-10757</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>2</td>\n",
       "      <td>29859</td>\n",
       "      <td>10758</td>\n",
       "      <td>2986</td>\n",
       "      <td>2-10758</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23500</th>\n",
       "      <td>2</td>\n",
       "      <td>29859</td>\n",
       "      <td>10759</td>\n",
       "      <td>2987</td>\n",
       "      <td>2-10759</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23501 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id  sequence  video_frame  sequence_frame image_id annotations\n",
       "0             0     40258            0               0      0-0          []\n",
       "1             0     40258            1               1      0-1          []\n",
       "2             0     40258            2               2      0-2          []\n",
       "3             0     40258            3               3      0-3          []\n",
       "4             0     40258            4               4      0-4          []\n",
       "...         ...       ...          ...             ...      ...         ...\n",
       "23496         2     29859        10755            2983  2-10755          []\n",
       "23497         2     29859        10756            2984  2-10756          []\n",
       "23498         2     29859        10757            2985  2-10757          []\n",
       "23499         2     29859        10758            2986  2-10758          []\n",
       "23500         2     29859        10759            2987  2-10759          []\n",
       "\n",
       "[23501 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23501/23501 [01:00<00:00, 387.34it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-16</td>\n",
       "      <td>559</td>\n",
       "      <td>213</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>584.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-17</td>\n",
       "      <td>558</td>\n",
       "      <td>213</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>583.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-18</td>\n",
       "      <td>557</td>\n",
       "      <td>213</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>582.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-19</td>\n",
       "      <td>556</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>581.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-20</td>\n",
       "      <td>555</td>\n",
       "      <td>214</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>580.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11893</th>\n",
       "      <td>2-10628</td>\n",
       "      <td>92</td>\n",
       "      <td>532</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>112.0</td>\n",
       "      <td>550.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11894</th>\n",
       "      <td>2-10629</td>\n",
       "      <td>78</td>\n",
       "      <td>569</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>98.0</td>\n",
       "      <td>587.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>2-10630</td>\n",
       "      <td>65</td>\n",
       "      <td>606</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>85.5</td>\n",
       "      <td>624.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>2-10631</td>\n",
       "      <td>51</td>\n",
       "      <td>643</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>73.0</td>\n",
       "      <td>661.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11897</th>\n",
       "      <td>2-10632</td>\n",
       "      <td>38</td>\n",
       "      <td>681</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>61.0</td>\n",
       "      <td>699.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11898 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id    x    y   w   h  x_center  y_center classes\n",
       "0         0-16  559  213  50  32     584.0     229.0       0\n",
       "1         0-17  558  213  50  32     583.0     229.0       0\n",
       "2         0-18  557  213  50  32     582.0     229.0       0\n",
       "3         0-19  556  214  50  32     581.0     230.0       0\n",
       "4         0-20  555  214  50  32     580.0     230.0       0\n",
       "...        ...  ...  ...  ..  ..       ...       ...     ...\n",
       "11893  2-10628   92  532  40  37     112.0     550.5       0\n",
       "11894  2-10629   78  569  40  37      98.0     587.5       0\n",
       "11895  2-10630   65  606  41  37      85.5     624.5       0\n",
       "11896  2-10631   51  643  44  37      73.0     661.5       0\n",
       "11897  2-10632   38  681  46  37      61.0     699.5       0\n",
       "\n",
       "[11898 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_df = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h', 'x_center', 'y_center', 'classes'])\n",
    "\n",
    "# idx = 4761\n",
    "for idx in tqdm(range(len(df))):\n",
    "    image_id, annotations = df.iloc[idx][['image_id','annotations']]\n",
    "    annotations = ast.literal_eval(annotations)\n",
    "    # bbox = annotations[0]\n",
    "    for bbox in annotations:\n",
    "        x = bbox['x']\n",
    "        y = bbox['y']\n",
    "        w = bbox['width']\n",
    "        h = bbox['height']\n",
    "        x_center = x + w/2\n",
    "        y_center = y + h/2\n",
    "        new_df = new_df.append({'image_id':image_id,'x':x,'y':y,'w':w,'h':h,'x_center':x_center,'y_center':y_center,'classes':0}, ignore_index=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = list(set(new_df.image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4919/4919 [00:24<00:00, 202.93it/s]\n"
     ]
    }
   ],
   "source": [
    "source = 'train_images'\n",
    "import shutil as sh\n",
    "if True:\n",
    "    for fold in [0]:\n",
    "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
    "        for name,mini in tqdm(new_df.groupby('image_id')):\n",
    "            if name in val_index:\n",
    "                path2save = 'val2017/'\n",
    "            else:\n",
    "                path2save = 'train2017/'\n",
    "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                for mn in row:\n",
    "                    mn[1] = mn[1]/1280\n",
    "                    mn[3] = mn[3]/1280\n",
    "                    mn[2] = mn[2]/720\n",
    "                    mn[4] = mn[4]/720\n",
    "                    \n",
    "                row = row.astype(str)\n",
    "                for j in range(len(row)):\n",
    "                    text = ' '.join(row[j])\n",
    "                    f.write(text)\n",
    "                    f.write(\"\\n\")\n",
    "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "            video_id, video_frame = name.split('-')[:2]\n",
    "            sh.copy(\"input/{}/video_{}/{}.jpg\".format(source,video_id,video_frame),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_id'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=reef0.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=1, batch_size=-1, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=yolov5x_fold0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (Docker image), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 ðŸš€ 9cc4b7a torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7022326 parameters, 7022326 gradients\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 1280\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.76G total, 0.10G reserved, 0.08G allocated, 14.58G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     7022326           0         0.933         136.6         116.4      (1, 3, 1280, 1280)                    list\n",
      "     7022326           0         1.753         39.03         62.21      (2, 3, 1280, 1280)                    list\n",
      "     7022326           0         3.456         59.95         115.5      (4, 3, 1280, 1280)                    list\n",
      "     7022326           0         6.470         110.7         238.9      (8, 3, 1280, 1280)                    list\n",
      "     7022326           0        12.696         221.1         473.7     (16, 3, 1280, 1280)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 16 for CUDA:0 13.28G/14.76G (90%)\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'convertor/fold0/labels/train2017' images and labels...3936 foun\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: convertor/fold0/images/train2017/0-9470.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: convertor/fold0/labels/train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'convertor/fold0/labels/val2017' images and labels...983 found, 0 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: convertor/fold0/labels/val2017.cache\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels to runs/train/yolov5x_fold05/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.17 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov5x_fold05\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/0     13.2G     0.102   0.05773         0        61      1280:  58%|â–ˆâ–ˆâ–ˆ"
     ]
    }
   ],
   "source": [
    "# yolov5s < yolov5m < yolov5l < yolov5x\n",
    "# after test yolov5s, small batch/epoch size, apply them by your resourse\n",
    "# -1 to auto batch\n",
    "# you should use --img <img_size>\n",
    "!python train.py --img 1280 --batch -1 --epochs 1 --data reef0.yaml --weights yolov5s.pt --name yolov5x_fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/yolov5x_fold03/weights/best.pt'], source=convertor/fold0/images/val2017, imgsz=[720, 1280], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/det, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ e47541a torch 1.9.0+cu111 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "WARNING: --img-size [720, 1280] must be multiple of max stride 32, updating to [736, 1280]\n",
      "image 1/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1005.jpg: 736x1280 Done. (0.037s)\n",
      "image 2/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1006.jpg: 736x1280 Done. (0.037s)\n",
      "image 3/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-101.jpg: 736x1280 Done. (0.037s)\n",
      "image 4/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1023.jpg: 736x1280 Done. (0.037s)\n",
      "image 5/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1026.jpg: 736x1280 Done. (0.037s)\n",
      "image 6/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-104.jpg: 736x1280 Done. (0.037s)\n",
      "image 7/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-106.jpg: 736x1280 Done. (0.037s)\n",
      "image 8/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-107.jpg: 736x1280 Done. (0.037s)\n",
      "image 9/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-111.jpg: 736x1280 Done. (0.037s)\n",
      "image 10/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-113.jpg: 736x1280 Done. (0.037s)\n",
      "image 11/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-116.jpg: 736x1280 Done. (0.029s)\n",
      "image 12/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-117.jpg: 736x1280 Done. (0.029s)\n",
      "image 13/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11869.jpg: 736x1280 Done. (0.029s)\n",
      "image 14/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11870.jpg: 736x1280 Done. (0.029s)\n",
      "image 15/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11875.jpg: 736x1280 Done. (0.029s)\n",
      "image 16/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11877.jpg: 736x1280 Done. (0.028s)\n",
      "image 17/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11880.jpg: 736x1280 Done. (0.028s)\n",
      "image 18/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11888.jpg: 736x1280 Done. (0.029s)\n",
      "image 19/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11899.jpg: 736x1280 Done. (0.027s)\n",
      "image 20/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11904.jpg: 736x1280 Done. (0.027s)\n",
      "image 21/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11908.jpg: 736x1280 Done. (0.027s)\n",
      "image 22/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-11928.jpg: 736x1280 Done. (0.027s)\n",
      "image 23/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12173.jpg: 736x1280 Done. (0.027s)\n",
      "image 24/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12175.jpg: 736x1280 Done. (0.027s)\n",
      "image 25/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12179.jpg: 736x1280 Done. (0.027s)\n",
      "image 26/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12181.jpg: 736x1280 Done. (0.027s)\n",
      "image 27/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12184.jpg: 736x1280 Done. (0.027s)\n",
      "image 28/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12188.jpg: 736x1280 Done. (0.027s)\n",
      "image 29/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12190.jpg: 736x1280 Done. (0.027s)\n",
      "image 30/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12197.jpg: 736x1280 Done. (0.027s)\n",
      "image 31/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12208.jpg: 736x1280 Done. (0.027s)\n",
      "image 32/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12213.jpg: 736x1280 Done. (0.026s)\n",
      "image 33/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12214.jpg: 736x1280 Done. (0.026s)\n",
      "image 34/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12215.jpg: 736x1280 Done. (0.026s)\n",
      "image 35/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12221.jpg: 736x1280 Done. (0.026s)\n",
      "image 36/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12223.jpg: 736x1280 Done. (0.026s)\n",
      "image 37/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12224.jpg: 736x1280 Done. (0.026s)\n",
      "image 38/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12229.jpg: 736x1280 Done. (0.026s)\n",
      "image 39/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12244.jpg: 736x1280 Done. (0.023s)\n",
      "image 40/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12249.jpg: 736x1280 Done. (0.023s)\n",
      "image 41/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12250.jpg: 736x1280 Done. (0.023s)\n",
      "image 42/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12257.jpg: 736x1280 Done. (0.023s)\n",
      "image 43/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12258.jpg: 736x1280 Done. (0.023s)\n",
      "image 44/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12265.jpg: 736x1280 Done. (0.023s)\n",
      "image 45/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12269.jpg: 736x1280 Done. (0.023s)\n",
      "image 46/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12279.jpg: 736x1280 Done. (0.023s)\n",
      "image 47/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12280.jpg: 736x1280 Done. (0.023s)\n",
      "image 48/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12284.jpg: 736x1280 Done. (0.023s)\n",
      "image 49/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12287.jpg: 736x1280 Done. (0.023s)\n",
      "image 50/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12291.jpg: 736x1280 Done. (0.023s)\n",
      "image 51/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12293.jpg: 736x1280 Done. (0.023s)\n",
      "image 52/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12295.jpg: 736x1280 Done. (0.023s)\n",
      "image 53/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12306.jpg: 736x1280 Done. (0.023s)\n",
      "image 54/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12307.jpg: 736x1280 Done. (0.023s)\n",
      "image 55/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12308.jpg: 736x1280 Done. (0.023s)\n",
      "image 56/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-12309.jpg: 736x1280 Done. (0.023s)\n",
      "image 57/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-126.jpg: 736x1280 Done. (0.023s)\n",
      "image 58/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-130.jpg: 736x1280 Done. (0.023s)\n",
      "image 59/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-135.jpg: 736x1280 Done. (0.023s)\n",
      "image 60/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-141.jpg: 736x1280 Done. (0.023s)\n",
      "image 61/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-153.jpg: 736x1280 Done. (0.023s)\n",
      "image 62/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1541.jpg: 736x1280 Done. (0.023s)\n",
      "image 63/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1542.jpg: 736x1280 Done. (0.023s)\n",
      "image 64/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1552.jpg: 736x1280 Done. (0.023s)\n",
      "image 65/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1553.jpg: 736x1280 Done. (0.023s)\n",
      "image 66/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1564.jpg: 736x1280 Done. (0.023s)\n",
      "image 67/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-164.jpg: 736x1280 Done. (0.023s)\n",
      "image 68/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-165.jpg: 736x1280 Done. (0.023s)\n",
      "image 69/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1860.jpg: 736x1280 Done. (0.023s)\n",
      "image 70/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1865.jpg: 736x1280 Done. (0.023s)\n",
      "image 71/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1867.jpg: 736x1280 Done. (0.023s)\n",
      "image 72/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1872.jpg: 736x1280 Done. (0.023s)\n",
      "image 73/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1873.jpg: 736x1280 Done. (0.024s)\n",
      "image 74/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1877.jpg: 736x1280 Done. (0.024s)\n",
      "image 75/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1879.jpg: 736x1280 Done. (0.024s)\n",
      "image 76/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1882.jpg: 736x1280 Done. (0.024s)\n",
      "image 77/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1886.jpg: 736x1280 Done. (0.024s)\n",
      "image 78/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1891.jpg: 736x1280 Done. (0.024s)\n",
      "image 79/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1898.jpg: 736x1280 Done. (0.024s)\n",
      "image 80/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1900.jpg: 736x1280 Done. (0.024s)\n",
      "image 81/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1905.jpg: 736x1280 Done. (0.024s)\n",
      "image 82/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1912.jpg: 736x1280 Done. (0.026s)\n",
      "image 83/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1913.jpg: 736x1280 Done. (0.025s)\n",
      "image 84/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1914.jpg: 736x1280 Done. (0.025s)\n",
      "image 85/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-1921.jpg: 736x1280 Done. (0.025s)\n",
      "image 86/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-20.jpg: 736x1280 Done. (0.026s)\n",
      "image 87/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2271.jpg: 736x1280 Done. (0.026s)\n",
      "image 88/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2277.jpg: 736x1280 Done. (0.026s)\n",
      "image 89/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2280.jpg: 736x1280 Done. (0.026s)\n",
      "image 90/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2281.jpg: 736x1280 Done. (0.026s)\n",
      "image 91/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2282.jpg: 736x1280 Done. (0.026s)\n",
      "image 92/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2283.jpg: 736x1280 Done. (0.026s)\n",
      "image 93/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2287.jpg: 736x1280 Done. (0.026s)\n",
      "image 94/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2289.jpg: 736x1280 Done. (0.026s)\n",
      "image 95/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2294.jpg: 736x1280 Done. (0.026s)\n",
      "image 96/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2297.jpg: 736x1280 Done. (0.026s)\n",
      "image 97/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2306.jpg: 736x1280 Done. (0.026s)\n",
      "image 98/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2321.jpg: 736x1280 Done. (0.026s)\n",
      "image 99/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2322.jpg: 736x1280 Done. (0.026s)\n",
      "image 100/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2325.jpg: 736x1280 Done. (0.026s)\n",
      "image 101/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2326.jpg: 736x1280 Done. (0.026s)\n",
      "image 102/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2333.jpg: 736x1280 Done. (0.026s)\n",
      "image 103/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-2335.jpg: 736x1280 Done. (0.026s)\n",
      "image 104/983 /workspace/cutiekath/quickstarter-yolov5/convertor/fold0/images/val2017/0-238.jpg: 736x1280 Done. (0.026s)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 243, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 238, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 102, in run\n",
      "    for path, im, im0s, vid_cap, s in dataset:\n",
      "  File \"/workspace/cutiekath/quickstarter-yolov5/utils/datasets.py\", line 218, in __next__\n",
      "    img0 = cv2.imread(path)  # BGR\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights runs/train/yolov5x_fold04/weights/best.pt --source convertor/fold0/images/val2017 --img 720 1280 --project runs/det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
